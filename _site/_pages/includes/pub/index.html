<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->





<title>Ziyu Guo - Homepage</title>







<meta property="og:locale" content="en">
<meta property="og:site_name" content="Ziyu Guo">
<meta property="og:title" content="Ziyu Guo">


  <link rel="canonical" href="http://localhost:4000/_pages/includes/pub/">
  <meta property="og:url" content="http://localhost:4000/_pages/includes/pub/">











<!-- end SEO -->


<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="assets/css/main.css">

<meta http-equiv="cleartype" content="on">
<head>
  <base target="_blank">
</head>
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=20250101">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png?v=20250101">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png?v=20250101">
<link rel="shortcut icon" href="/images/favicon.ico?v=20250101">
<link rel="manifest" href="/images/site.webmanifest?v=20250101">

<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<style>
.show-figure-btn {
  background-color: #d3d3d3;
  color: #333;
  border: none;
  padding: 5px 10px;
  border-radius: 3px;
  cursor: pointer;
  font-size: 12px;
  margin-left: 5px;
}

.show-figure-btn:hover {
  background-color: #c0c0c0;
}

.show-figure-btn.active {
  background-color: #e0e0e0;
}
</style>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg masthead__menu-home-item"><a href="#about-me">Homepage</a></li>
          
            <li class="masthead__menu-item"><a href="/#about-me">About Me</a></li>
          
            <li class="masthead__menu-item"><a href="/#-news">News</a></li>
          
            <li class="masthead__menu-item"><a href="/#-publications">Publications</a></li>
          
            <li class="masthead__menu-item"><a href="/#-educations">Educations</a></li>
          
            <li class="masthead__menu-item"><a href="/#-academic-service">Academic Service</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div id="main" role="main">
      
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person" class="profile_box">

  <div class="author__avatar">
    <img src="images/photo.jpg" class="author__avatar" alt="Ziyu Guo">
  </div>

  <div class="author__content">
    <h3 class="author__name">Ziyu Guo</h3>
    
  </div>

  <div class="author__urls-wrapper">
    <!-- <button class="btn btn--inverse">More Info & Contact</button> -->
    <ul class="author__urls social-icons">
      
        <li><div style="white-space: normal; margin-bottom: 1em;">Ph.D. Candidate at CUHK</div></li>
      
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Hong Kong S.A.R., China</li>
      
      
      
        <li><a href="https://scholar.google.com.hk/citations?user=S9GLetwAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
        <li><a href="https://github.com/ZiyuGuo99"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
        <li><a href="https://www.linkedin.com/in/ziyu-guo-702a3a2aa"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
      
      
        <li><a href="mailto:guoziyu86@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
        <li><i class="fab fa-fw fa-weixin" aria-hidden="true"></i> WeChat: Zoey_Guo0917</li>
      
      
      
       
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
      <div class="author__urls_sm">
      
        <a href="https://scholar.google.com.hk/citations?user=S9GLetwAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i></a>
      
      
        <a href="https://github.com/ZiyuGuo99"><i class="fab fa-fw fa-github" aria-hidden="true"></i></a>
      
      
        <a href="https://www.linkedin.com/in/ziyu-guo-702a3a2aa"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i></a>
      
      
        <a href="mailto:guoziyu86@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i></a>
      
      
        <span title="WeChat: Zoey_Guo0917"><i class="fab fa-fw fa-weixin" aria-hidden="true"></i></span>
      
      
      
       
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </div>
  </div>
</div>

  
  </div>

    
      <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
        <meta itemprop="headline" content="üìù Publications">
        <div class="page__inner-wrap">
          <section class="page__content" itemprop="text">
            <h1 id="-publications">üìù Publications</h1>

<!-- <div style="background-color: #f0f7ff; border-left: 4px solid #0066cc; padding: 12px 16px; margin-bottom: 20px; border-radius: 4px;">
  <strong>üí°</strong> Click "Show Figure" to view the corresponding figure.
</div> -->

<h2 id="cotcof-reasoning-for-visual-generation">CoT/CoF Reasoning for Visual Generation</h2>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="report-tag">Technical Report</span> <a href="https://arxiv.org/abs/2510.26802">Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study on the MME-CoF Benchmark</a>.<br />
    <strong>Ziyu Guo</strong>*, Xinyan Chen*, Renrui Zhang*, Ruichuan An*, Yu Qi*, Dongzhi Jiang, Xiangtai Li, Manyuan Zhang, Hongsheng Li, Pheng-Ann Heng.<br />[<a href="https://arxiv.org/abs/2510.26802">PDF</a>] [<a href="https://github.com/ZiyuGuo99/MME-CoF">Code</a>] [<a href="https://video-cof.github.io/">Homepage</a>] [<a href="https://huggingface.co/datasets/ZiyuG/MME-CoF">Benchmark</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-1', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-1" style="display: none;">
    <img src="images/papers/video-cof.jpg" alt="MME-CoF" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="preprint-tag">arXiv</span> <a href="https://arxiv.org/pdf/2501.13926">Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step</a>.<br />
    <strong>Ziyu Guo</strong>*, Renrui Zhang*, Chengzhuo Tong*, Zhizheng Zhao*, Peng Gao, Hongsheng Li#, Pheng-Ann Heng#.<br />[<a href="https://arxiv.org/pdf/2501.13926">PDF</a>] [<a href="https://github.com/ZiyuGuo99/Image-Generation-CoT">Code</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-2', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-2" style="display: none;">
    <img src="images/papers/cot.jpg" alt="Image Generation CoT" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">NeurIPS 2025</span> <a href="https://arxiv.org/pdf/2505.00703">T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT</a>.<br />
    Dongzhi Jiang*, <strong>Ziyu Guo</strong>*, Renrui Zhang*, Zhuofan Zong, Hao Li, Le Zhuo, Shilin Yan, Pheng-Ann Heng#, Hongsheng Li#.<br />[<a href="https://arxiv.org/pdf/2505.17017">PDF</a>] [<a href="https://github.com/CaraJ7/T2I-R1">Code</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-3', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-3" style="display: none;">
    <img src="images/papers/t2i-r1.png" alt="T2I-R1" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">NeurIPS 2025</span> <a href="https://arxiv.org/pdf/2505.17017">Delving into RL for Image Generation with CoT: A Study on DPO vs. GRPO</a>.<br />
    Chengzhuo Tong*, <strong>Ziyu Guo</strong>*, Renrui Zhang*, Wenyu Shan*, Xinyu Wei, Zhenghao Xing, Hongsheng Li#, Pheng-Ann Heng#.<br />[<a href="https://arxiv.org/pdf/2505.17017">PDF</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-4', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-4" style="display: none;">
    <img src="images/papers/delving.png" alt="Delving" />
  </div>
</div>

<h2 id="cot-reasoning-for-visual-understanding">CoT Reasoning for Visual Understanding</h2>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">ACL 2025</span> <a href="https://arxiv.org/pdf/2503.10627">SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems</a>.<br />
    <strong>Ziyu Guo</strong>*, Renrui Zhang*, Hao Chen*, Jialin Gao*, Dongzhi Jiang, Jiaze Wang, Pheng-Ann Heng#.<br />[<a href="https://sciverse-cuhk.github.io/">Webpage</a>] [<a href="https://huggingface.co/datasets/ZiyuG/SciVerse">Benchmark</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-5', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-5" style="display: none;">
    <img src="images/papers/sciverse.png" alt="SciVerse" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">ICML 2025</span> <a href="https://arxiv.org/pdf/2502.09621">MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency</a>.<br />
    Dongzhi Jiang*, Renrui Zhang*, <strong>Ziyu Guo</strong>, Yanwei Li, Yu Qi, Xinyan Chen, Liuhui Wang, Jianhan Jin, Claire Guo, Shen Yan, Bo Zhang, Chaoyou Fu, Peng Gao, Hongsheng Li#.<br />[<a href="https://arxiv.org/pdf/2502.09621">PDF</a>] [<a href="https://github.com/CaraJ7/MME-CoT">Code</a>] [<a href="https://mmecot.github.io/">Webpage</a>] [<a href="https://huggingface.co/datasets/CaraJ/MME-CoT">Benchmark</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-6', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-6" style="display: none;">
    <img src="images/papers/mme-cot.png" alt="MME-CoT" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">ICLR 2025</span> <a href="https://arxiv.org/pdf/2407.08739">MAVIS: Mathematical Visual Instruction Tuning with an Automatic Data Engine</a>.<br />
    Renrui Zhang, Xinyu Wei, Dongzhi Jiang, <strong>Ziyu Guo</strong>, Shicheng Li, Yichi Zhang, Chengzhuo Tong, Jiaming Liu, Aojun Zhou, Bin Wei, Shanghang Zhang, Peng Gao, Chunyuan Li, Hongsheng Li#.<br />[<a href="https://arxiv.org/pdf/2407.08739">PDF</a>] [<a href="https://github.com/ZrrSkywalker/MAVIS">Code</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-7', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-7" style="display: none;">
    <img src="images/papers/mavis.png" alt="MAVIS" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">ECCV 2024</span> <a href="https://arxiv.org/pdf/2403.14624">MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?</a>.<br />
    Renrui Zhang, Dongzhi Jiang, Yichi Zhang, Haokun Lin, <strong>Ziyu Guo</strong>, Pengshuo Qiu, Aojun Zhou, Pan Lu, Kai-Wei Chang, Yu Qiao, Peng Gao, Hongsheng Li.<br />[<a href="https://mathverse-cuhk.github.io/">Webpage</a>] [<a href="https://huggingface.co/datasets/AI4Math/MathVerse">Benchmark</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-8', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-8" style="display: none;">
    <img src="images/papers/mathverse.png" alt="MathVerse" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">ICLR 2025</span> <a href="https://arxiv.org/pdf/2305.03048.pdf">MMSearch: Benchmarking the Potential of Large Models as Multi-modal Search Engines</a>.<br />
    Dongzhi Jiang*, Renrui Zhang*, <strong>Ziyu Guo</strong>, Yanmin Wu, Jiayi Lei, Pengshuo Qiu, Pan Lu, Zehui Chen, Guanglu Song, Peng Gao, Yu Liu, Chunyuan Li, Hongsheng Li#.<br />[<a href="https://arxiv.org/pdf/2409.12959">PDF</a>] [<a href="https://github.com/CaraJ7/MMSearch">Code</a>] [<a href="https://mmsearch.github.io/">Webpage</a>] [<a href="https://huggingface.co/datasets/CaraJ/MMSearch">Dataset</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-9', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-9" style="display: none;">
    <img src="images/papers/teaser.png" alt="MMSearch" />
  </div>
</div>

<h2 id="3d-large-models">3D Large Models</h2>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="preprint-tag">arXiv</span> <a href="https://arxiv.org/pdf/2309.00615">Point-Bind &amp; Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding, Generation, and Instruction Following</a>.<br />
    <strong>Ziyu Guo</strong>*, Renrui Zhang*, Xiangyang Zhu, Yiwen Tang, Xianzheng Ma, Jiaming Han, Kexin Chen, Peng Gao, Xianzhi Li#, Hongsheng Li, Pheng-Ann Heng.<br />[<a href="https://arxiv.org/pdf/2309.00615">PDF</a>] [<a href="https://github.com/ZiyuGuo99/Point-Bind_Point-LLM">Code</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-10', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-10" style="display: none;">
    <img src="images/papers/pointbind.png" alt="Point-Bind" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="preprint-tag">arXiv</span> <a href="https://arxiv.org/abs/2502.09620">Exploring the Potential of Encoder-free Architectures in 3D LMMs</a>.<br />
    Yiwen Tang*, <strong>Ziyu Guo</strong>*, Zhuhao Wang*, Renrui Zhang, Qizhi Chen, Junli Liu, Delin Qu, Zhigang Wang, Dong Wang, Xuelong Li, Bin Zhao.<br />[<a href="https://arxiv.org/abs/2502.09620">PDF</a>] [<a href="https://github.com/ZiyuGuo99/Point-Bind_Point-LLM">Code</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-11', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-11" style="display: none;">
    <img src="images/papers/enel.png" alt="Encoder-free" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="report-tag">Technical Report</span> <a href="https://arxiv.org/pdf/2408.16768">SAM2Point: Segment Any 3D as Videos in Zero-shot and Promptable Manners</a>.<br />
    <strong>Ziyu Guo</strong>*, Renrui Zhang*, Xiangyang Zhu*, Chengzhuo Tong, Peng Gao, Chunyuan Li, Pheng-Ann Heng#.<br />[<a href="https://arxiv.org/pdf/2408.16768">PDF</a>] [<a href="https://github.com/ZiyuGuo99/SAM2Point">Code</a>] [<a href="https://sam2point.github.io/">Webpage</a>] [<a href="https://huggingface.co/spaces/ZiyuG/SAM2Point">Demo</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-12', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-12" style="display: none;">
    <img src="images/papers/sam2point.png" alt="SAM2Point" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">CVPR 2022</span> <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_PointCLIP_Point_Cloud_Understanding_by_CLIP_CVPR_2022_paper.pdf">PointCLIP: Point Cloud Understanding by CLIP</a>.<br />
    Renrui Zhang*, <strong>Ziyu Guo</strong>*, Wei Zhang, Kunchang Li, Xupeng Miao, Bin Cui, Yu Qiao, Peng Gao, Hongsheng Li#.<br />[<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_PointCLIP_Point_Cloud_Understanding_by_CLIP_CVPR_2022_paper.pdf">PDF</a>] [<a href="https://github.com/ZrrSkywalker/PointCLIP">Code</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-13', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-13" style="display: none;">
    <img src="images/papers/pointclip.png" alt="PointCLIP" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">NeurIPS 2022</span> <a href="https://arxiv.org/pdf/2205.14401.pdf">Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud Pre-training</a>.<br />
    Renrui Zhang, <strong>Ziyu Guo</strong>, Rongyao Fang, Bin Zhao, Dong Wang, Yu Qiao, Hongsheng Li, Peng Gao#.<br />[<a href="https://arxiv.org/pdf/2205.14401.pdf">PDF</a>] [<a href="https://github.com/ZrrSkywalker/Point-M2AE">Code</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-14', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-14" style="display: none;">
    <img src="images/papers/pointm2ae.png" alt="Point-M2AE" />
  </div>
</div>

<h2 id="3d--multi-modality-learning">3D &amp; Multi-modality Learning</h2>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">ICCV 2025</span> <a href="https://arxiv.org/pdf/2503.21775">StyleMotif: Multi-Modal Motion Stylization using Style-Content Cross Fusion</a>.<br />
    <strong>Ziyu Guo</strong>, Young Yoon Lee, Joseph Liu, Yizhak Ben-Shabat, Victor Zordan, Mubbasir Kapadia#.<br />[<a href="https://stylemotif.github.io/">Webpage</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-15', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-15" style="display: none;">
    <img src="images/papers/stylemotif.png" alt="StyleMotif" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">ICLR 2024</span> <a href="https://arxiv.org/pdf/2305.03048.pdf">Personalize Segment Anything Model with One Shot</a>.<br />
    Renrui Zhang, Zhengkai Jiang*, <strong>Ziyu Guo</strong>*, Shilin Yan, Junting Pan, Hao Dong, Peng Gao, Hongsheng Li#.<br />[<a href="https://arxiv.org/pdf/2305.03048.pdf">PDF</a>] [<a href="https://github.com/ZrrSkywalker/Personalize-SAM">Code</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-16', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-16" style="display: none;">
    <img src="images/papers/persam.png" alt="PerSAM" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">ICCV 2023</span> <a href="https://arxiv.org/pdf/2305.03048.pdf">ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with GPT and Prototype Guidance</a>.<br />
    <strong>Ziyu Guo</strong>*, Yiwen Tang*, Renrui Zhang*, Dong Wang, Zhigang Wang, Bin Zhao.<br />[<a href="https://arxiv.org/pdf/2303.16894.pdf">PDF</a>] [<a href="https://github.com/Ivan-Tang-3D/ViewRefer3D">Code</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-17', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-17" style="display: none;">
    <img src="images/papers/viewrefer.png" alt="ViewRefer" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">AAAI 2023</span> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25152/24924">CALIP: Zero-Shot Enhancement of CLIP with Non-Parametric Attention</a>.<br />
    <strong>Ziyu Guo</strong>*, Renrui Zhang*, Longtian Qiu*, Xupeng Miao, Bin Cui#.<br />[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/25152/24924">PDF</a>] [<a href="https://github.com/ZiyuGuo99/CALIP">Code</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-18', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-18" style="display: none;">
    <img src="images/papers/calip.png" alt="CALIP" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">IJCAI 2023</span> <a href="https://arxiv.org/pdf/2302.14007">Joint-MAE: 2D-3D Joint Masked Autoencoders for 3D Point Cloud Pre-training</a>.<br />
    <strong>Ziyu Guo</strong>*, Renrui Zhang*, Longtian Qiu, Xianzhi Li#, Pheng-Ann Heng.<br />[<a href="https://arxiv.org/pdf/2302.14007">PDF</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-19', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-19" style="display: none;">
    <img src="images/papers/jointmae.png" alt="Joint-MAE" />
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-text">
    <span class="conference-tag">WACV 2023</span> <a href="https://arxiv.org/pdf/2303.00703.pdf">Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis</a>.<br />
    Renrui Zhang, Liuhui Wang, <strong>Ziyu Guo</strong>, Jianbo Shi#.<br />[<a href="https://arxiv.org/pdf/2303.00703.pdf">PDF</a>] <button class="show-figure-btn" onclick="toggleFigure('fig-20', this)">Show Figure</button>
  </div>
  <div class="paper-box-image-below" id="fig-20" style="display: none;">
    <img src="images/papers/wacv.png" alt="WACV" />
  </div>
</div>

<script>
function toggleFigure(figId, button) {
  var figure = document.getElementById(figId);
  
  if (figure.style.display === 'none' || figure.style.display === '') {
    figure.style.display = 'block';
    button.innerHTML = 'Hide Figure';
    button.classList.add('active');
  } else {
    figure.style.display = 'none';
    button.innerHTML = 'Show Figure';
    button.classList.remove('active');
  }
}
</script>


          </section>
        </div>
      </article>
    </div>

    <script src="assets/js/main.min.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-111540567-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', "UA-111540567-4");
</script>


<script>
    $(document).ready(function () {
        
        var gsDataBaseUrl = 'https://cdn.jsdelivr.net/gh/ZiyuGuo99/ZiyuGuo99.github.io@'
        
        $.getJSON(gsDataBaseUrl + "google-scholar-stats/gs_data.json", function (data) {
            var totalCitation = data['citedby']
            document.getElementById('total_cit').innerHTML = totalCitation;
            var citationEles = document.getElementsByClassName('show_paper_citations')
            Array.prototype.forEach.call(citationEles, element => {
                var paperId = element.getAttribute('data')
                var numCitations = data['publications'][paperId]['num_citations']
                element.innerHTML = '| Citations: ' + numCitations;
            });
        });
    })
</script>

    <div id="footer">
      <div id="footer-text"></div>
    </div>
    <div style="text-align: center; max-width: 150px; margin: 0 auto;">
      <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=-b6xtMdAq7FTxXU9vts4l5Q3gOSFeRHtbw5k1gcql24"></script>
    </div>
      <p><center> &copy; Ziyu Guo </center></p>
    </div>
  </body>
</html>
